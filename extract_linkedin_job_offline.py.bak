#!/usr/bin/env python3
# coding: utf-8
"""
extract_linkedin_job_offline.py
100% local. Lee vacante.txt (o stdin), extrae cargo/empresa/requerimientos con heur√≠sticas,
genera nueva_aplicacion.yaml y guarda el par original->prediccion en data/training_data.jsonl
para que t√∫ puedas revisar y usar localmente m√°s tarde.

Uso:
  python extract_linkedin_job_offline.py vacante.txt
  python extract_linkedin_job_offline.py --debug vacante.txt
  (o) python extract_linkedin_job_offline.py    # pega el texto y termina con Ctrl+D / Ctrl+Z+Enter
Salida:
  - nueva_aplicacion.yaml
  - data/training_data.jsonl (se a√±ade una l√≠nea con {"text":..., "yaml":...})
"""
import sys
import re
import json
from datetime import date
from textwrap import dedent
import argparse
import os
from pathlib import Path

# DEBUG flag (set in main)
DEBUG = False

# --- Resuelve rutas relativas respecto a la ubicaci√≥n del script (no al CWD) ---
SCRIPT_PATH = Path(__file__).resolve()
PROJECT_ROOT = SCRIPT_PATH.parent
DATA_DIR = PROJECT_ROOT / 'data'
DATA_DIR.mkdir(parents=True, exist_ok=True)

OUT_YAML = str(PROJECT_ROOT / 'nueva_aplicacion.yaml')
TRAIN_FILE = str(DATA_DIR / 'training_data.jsonl')
# --- fin de resoluci√≥n de rutas ---

BULLET_RE = re.compile(r'^\s*([¬∑\-\*\u2022]|\d+\.)\s*(.+)', re.UNICODE)
NOISE_PATTERNS = [
    r'logo', r'\bshare\b', r'show more options', r'easy apply', r'\bsave\b',
    r'\bfollow\b', r'promoted', r'job match summary', r'get personalized tips'
]
ROLE_KEYWORDS = [
    'analyst','analista','engineer','developer','manager','consultant','scientist',
    'coordinator','officer','specialist','administrator','architect','operations',
    'data','insight','insights','anal√≠tica','analytics','analisis'
]
OFFERS_HEADINGS_RE = re.compile(
    r'(Lo que ofrecemos|Lo que ofrecemos:|What we offer|What we offer:|üîπ Lo que ofrecemos|Lo que ofrecemosüîπ|Qu√© ofrecemos)',
    re.I
)

# company indicators shared across heuristics (strong signals)
_COMPANY_INDICATORS = [
    r'\binc\b', r'\bllc\b', r'\bco\b', r'\bcompany\b', r'\bsa\b', r'\bs\.a\b',
    r'\bltda\b', r'\bcorp\b', r'\btechnologies\b', r'\bsolutions\b', r'\bgroup\b',
    r'\bholdings\b', r'\bgmbh\b', r'\bag\b', r'\bltd\b'
]


def read_input(path=None):
    if path:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    else:
        return sys.stdin.read()


def simple_clean_lines(text):
    return [l.strip() for l in text.splitlines() if l.strip()]


def normalize_company_candidate(line):
    """
    Normaliza una l√≠nea candidata a company:
    - elimina sufijo 'logo' y badges comunes
    - elimina separadores repetidos y espacios extras
    - devuelve versi√≥n limpia para evaluar
    """
    if not line:
        return line
    s = line.strip()
    # eliminar tokens 'logo' al final o entre par√©ntesis
    s = re.sub(r'\s*\(logo\)\s*$', '', s, flags=re.I)
    s = re.sub(r'\s*logo\s*$', '', s, flags=re.I)
    # eliminar prefijos/sufijos 'save', 'promoted' etc.
    s = re.sub(r'\b(save|promoted|easy apply|share)\b', '', s, flags=re.I)
    # colapsar m√∫ltiples separadores (¬∑, - , ‚Ä¢)
    s = re.sub(r'[¬∑‚Ä¢\-‚Äì‚Äî]+', '¬∑', s)
    s = re.sub(r'\s+', ' ', s).strip()
    # trim trailing punctuation
    s = s.rstrip('.,;:')
    return s


def is_noise_line(ln):
    """
    Decide si una l√≠nea es 'ruido' (no √∫til) o no.
    - Excepci√≥n: si la l√≠nea termina en 'logo' pero contiene un nombre (ej. 'StaffBridge Inc logo'),
      no la marcamos como ruido aqu√≠ ‚Äî la normalizamos y la dejamos que la eval√∫e looks_like_company.
    """
    if not ln:
        return True

    s = ln.strip()
    # Si es algo como "CompanyName logo" o "CompanyName (logo)", no lo tratamos como ruido aqu√≠
    m_logo = re.match(r'^(?P<name>.+?)\s*(?:\(logo\)|logo)\s*$', s, re.I)
    if m_logo:
        name = m_logo.group('name').strip()
        # Si la parte del nombre tiene capitalizaci√≥n o parece compa√±√≠a/rol, no la descartamos
        if re.search(r'[A-Z√Å√â√ç√ì√ö√ë]', name) or re.search(r'\b(inc|llc|ltda|corp|company|s\.a|sa|co|gmbh|ltd)\b', name, re.I):
            return False

    l = s.lower()
    # patrones ya existentes de ruido
    for p in NOISE_PATTERNS:
        if re.search(p, l):
            return True

    # metadata t√≠pica (n¬∫ aplicantes, "days ago", duraciones)
    if re.search(r'\b\d+\s+applicants?\b', l):
        return True
    if re.search(r'\b\d+\s+days?\s+ago\b', l) or re.search(r'\b\d+(h|m|min|hrs?|hours?)\b', l):
        return True
    if re.search(r'\b(days?|ago|applicants?|applicant|remote|full-time|part-time|hybrid|contract|easy apply|promoted)\b', l):
        return True

    # l√≠neas con muchos s√≠mbolos o solo n√∫meros/fechas
    if re.match(r'^[\d\W_]+$', l):
        return True
    if len(l) <= 3:
        return True
    if re.match(r'^(share|see more|show more|apply|easy apply|save|promoted|matches your job preferences)$', s, re.I):
        return True
    return False


def looks_like_role(line, strict=False, lines_context=None):
    """
    strict=False (default): detecta role si contiene ROLE_KEYWORDS;
      la heur√≠stica de capitalizaci√≥n solo se usa si no encontramos roles por keyword en el doc.
    strict=True: fuerza el uso de keywords y NO usa capitalizaci√≥n (√∫til para comprobaciones conservadoras).
    Si pasamos lines_context (lista de l√≠neas del doc), la funci√≥n puede decidir si aplicar fallback por capitalizaci√≥n.
    """
    if not line:
        return False
    l = line.lower()
    # 1) Prefer keyword match (robusto)
    for kw in ROLE_KEYWORDS:
        if re.search(r'\b' + re.escape(kw) + r'\b', l):
            return True

    # 2) Fallback por capitalizaci√≥n: solo si no hay roles por keyword en el contexto
    if strict:
        return False

    if lines_context is not None:
        # check if any line in the first 40 lines contains a ROLE_KEYWORD
        found_kw = False
        for ln in lines_context[:40]:
            for kw in ROLE_KEYWORDS:
                if re.search(r'\b' + re.escape(kw) + r'\b', ln.lower()):
                    found_kw = True
                    break
            if found_kw:
                break
        if found_kw:
            # si ya hay roles por keyword en el documento, NO use cap heuristics para evitar confundir company
            return False

    # apply capitalization heuristic as last resort
    words = [w for w in line.split() if w]
    if 1 < len(words) <= 12:
        cap = sum(1 for w in words if w and (w[0].isupper() or '&' in w))
        if cap >= max(1, len(words)//2):
            return True
    return False


def looks_like_company(line):
    """
    Heur√≠stica conservadora para company.
    - normaliza la l√≠nea (quita 'logo' etc.)
    - acepta si contiene indicadores fuertes (Inc/LLC/Co/etc)
    - acepta si tiene capitalizaci√≥n t√≠pica de nombre y no parece role o metadata
    """
    if not line or not line.strip():
        return False
    s = normalize_company_candidate(line)
    ll = s.lower()

    # descartar metadata obvia
    if re.search(r'\b\d+\s+applicants?\b', ll) or re.search(r'\b\d+\s+days?\s+ago\b', ll):
        return False
    if re.search(r'\b(remote|full-time|part-time|hybrid|contract|easy apply|promoted)\b', ll):
        return False
    # strong indicator present -> accept
    for patt in _COMPANY_INDICATORS:
        if re.search(patt, ll):
            return True

    # if it's short and TitleCase and not a role, accept conservatively
    words = [w for w in s.split() if w]
    if 1 < len(words) <= 6:
        cap = sum(1 for w in words if w and w[0].isupper())
        if cap >= max(1, len(words)//2) and not looks_like_role(s, strict=True):
            return True

    return False


def company_score(candidate, role_idx=None, cand_idx=None):
    s = normalize_company_candidate(candidate or "")
    ll = s.lower()
    score = 0
    # strong indicators
    for patt in _COMPANY_INDICATORS:
        if re.search(patt, ll):
            score += 5
    # not noise
    if s and not is_noise_line(s):
        score += 3
    # short and TitleCase
    words = [w for w in s.split() if w]
    if 1 < len(words) <= 6:
        cap = sum(1 for w in words if w and w[0].isupper())
        if cap >= max(1, len(words)//2):
            score += 2
    # proximity bonus
    if role_idx is not None and cand_idx is not None:
        dist = abs(role_idx - cand_idx)
        if dist == 0:
            score += 3
        elif dist == 1:
            score += 2
        elif dist == 2:
            score += 1
    # penalty for metadata
    if re.search(r'\b(days?|ago|applicants?|applicant)\b', ll):
        score -= 10
    return score


def guess_title_and_company(text):
    """
    Heur√≠stica mejorada:
    - eval√∫a patrones inline
    - busca rol y compa√±√≠a cercanos validando company con looks_like_company y usando scoring
    - si no hay compa√±√≠a cercana, busca globalmente company-like lines (normalizadas), priorizando indicadores fuertes
    - maneja el caso "CompanyName [logo]" seguido por "Role" (company precede role).
    """
    lines = simple_clean_lines(text)

    # 1) inline patterns (Title at Company / Title ¬∑ Company)
    for i in range(min(8, len(lines))):
        ln = lines[i]
        m = re.match(r'^(?P<A>.+?)\s+at\s+(?P<B>.+)$', ln, re.I)
        if m:
            A = m.group('A').strip(); B = m.group('B').strip()
            if looks_like_role(A, lines_context=lines) and looks_like_company(B):
                return A, normalize_company_candidate(B)
            if looks_like_role(B, lines_context=lines) and looks_like_company(A):
                return B, normalize_company_candidate(A)
        m2 = re.match(r'^(?P<A>.+?)\s*[¬∑\-‚Äì‚Äî]\s*(?P<B>.+)$', ln)
        if m2:
            A = m2.group('A').strip(); B = m2.group('B').strip()
            if looks_like_role(A, lines_context=lines) and looks_like_company(B):
                return A, normalize_company_candidate(B)
            if looks_like_role(B, lines_context=lines) and looks_like_company(A):
                return B, normalize_company_candidate(A)

    # 2) build candidates list (skip noise)
    candidates = []
    for i, ln in enumerate(lines[:120]):
        if is_noise_line(ln):
            continue
        candidates.append((i, ln))

    # 3) scan candidates: when find a role, score nearby company candidates and pick best
    for idx, ln in candidates:
        if looks_like_role(ln, lines_context=lines):
            # gather candidate lines in window
            window_start = max(0, idx - 6)
            window_end = min(len(lines), idx + 6)
            cand_list = []
            for cand_idx in range(window_start, window_end):
                if cand_idx == idx:
                    continue
                cand_line = normalize_company_candidate(lines[cand_idx])
                if not cand_line:
                    continue
                if is_noise_line(cand_line):
                    continue
                sc = company_score(cand_line, role_idx=idx, cand_idx=cand_idx)
                cand_list.append((sc, cand_idx, cand_line))
            if cand_list:
                cand_list.sort(key=lambda x: x[0], reverse=True)
                best_score, best_idx, best_cand = cand_list[0]
                if DEBUG:
                    print(f"[DEBUG] role_idx={idx} role='{ln}' candidates(window {window_start}-{window_end}):")
                    for sc, ci, cl in cand_list:
                        print(f"  score={sc:3d} idx={ci} -> {cl!r}")
                    print(f"  -> chosen score={best_score} idx={best_idx} company={best_cand!r}")
                if best_score > 0:
                    return ln, best_cand
            # if none chosen by score, fall back to nearby validated company (conservative)
            # (existing heuristics)
            company = ""
            for j in range(idx-1, max(-1, idx-6), -1):
                if j < 0:
                    break
                cand = normalize_company_candidate(lines[j])
                if not is_noise_line(cand) and not looks_like_role(cand, lines_context=lines) and looks_like_company(cand):
                    company = cand
                    break
            if not company:
                for j in range(idx+1, min(len(lines), idx+6)):
                    cand = normalize_company_candidate(lines[j])
                    if not is_noise_line(cand) and not looks_like_role(cand, lines_context=lines) and looks_like_company(cand):
                        company = cand
                        break
            if company:
                return ln, company
            # else continue scanning other candidates

    # 4) company-before-role case: if a line looks like company, try find role near it
    for i, ln in enumerate(lines[:120]):
        ln_norm = normalize_company_candidate(ln)
        if looks_like_company(ln_norm) and not is_noise_line(ln_norm):
            # search below for role first
            for j in range(i+1, min(len(lines), i+6)):
                if looks_like_role(lines[j], lines_context=lines):
                    if DEBUG:
                        print(f"[DEBUG] detected company-before-role: company_line_idx={i}, company={ln_norm!r}, role_idx={j}, role={lines[j]!r}")
                    return lines[j], ln_norm
            # search above
            for j in range(i-1, max(-1, i-6), -1):
                if j < 0:
                    break
                if looks_like_role(lines[j], lines_context=lines):
                    if DEBUG:
                        print(f"[DEBUG] detected company-before-role (above): company_line_idx={i}, company={ln_norm!r}, role_idx={j}, role={lines[j]!r}")
                    return lines[j], ln_norm

    # 5) heuristics for first two lines
    if len(lines) >= 2:
        if '¬∑' in lines[1]:
            parts = [p.strip() for p in lines[1].split('¬∑')]
            if parts:
                for p in parts:
                    np = normalize_company_candidate(p)
                    if looks_like_company(np):
                        return lines[0], np
                first = normalize_company_candidate(parts[0])
                if first and not re.search(r'\b(days?|ago|applicants?)\b', first.lower()):
                    return lines[0], first
        second_norm = normalize_company_candidate(lines[1])
        if looks_like_company(second_norm):
            return lines[0], second_norm

    # 6) fallback global search (prefer strong indicators)
    role_candidate = None
    for idx, ln in candidates:
        if looks_like_role(ln, lines_context=lines):
            role_candidate = ln
            break
    for ln in lines:
        if is_noise_line(ln) or looks_like_role(ln, lines_context=lines):
            continue
        cand = normalize_company_candidate(ln)
        strong = any(re.search(p, cand.lower()) for p in _COMPANY_INDICATORS)
        if strong or looks_like_company(cand):
            if role_candidate:
                return role_candidate, cand
            else:
                return "", cand

    # 7) last resort: return first role candidate without company, or empty
    for idx, ln in candidates:
        if looks_like_role(ln, lines_context=lines):
            return ln, ""
    if candidates:
        return candidates[0][1], ""
    return ("", "")


def remove_offers_section(text):
    m = OFFERS_HEADINGS_RE.search(text)
    if m:
        return text[:m.start()]
    return text


def extract_bullets_from_text(text):
    text = remove_offers_section(text)
    lines = text.splitlines()
    items = []
    for ln in lines:
        m = BULLET_RE.match(ln)
        if m:
            items.append(m.group(2).strip())
        else:
            if ln.strip().startswith('üîπ') or ln.strip().startswith('¬∑'):
                items.append(ln.strip().lstrip('üîπ¬∑').strip())
            else:
                if items and ln.strip():
                    items[-1] += " " + ln.strip()
    seen = set(); out = []
    for it in items:
        k = re.sub(r'\s+', ' ', it.lower()).strip()
        if k and k not in seen:
            seen.add(k); out.append(it)
    return out


def clean_requirement(r):
    s = r.strip().strip('"').strip("'")
    s = re.sub(r'\s*[:\u2014\u2013]\s*', '. ', s, count=1)
    s = re.sub(r'\s-\s', '. ', s, count=1)
    s = s.lstrip('üîπ¬∑‚Ä¢').strip()
    s = re.sub(r'\s+', ' ', s)
    if s and not re.search(r'[\.!?]$', s):
        s = s + '.'
    if s and s[0].islower():
        s = s[0].upper() + s[1:]
    return s


def format_yaml(cargo, empresa, fecha_iso, descripcion_block, requirements):
    lines = []
    lines.append(f'cargo: "{cargo}"')
    lines.append(f'empresa: "{empresa}"')
    lines.append(f'fecha: "{fecha_iso}"')
    lines.append('descripcion: |')
    for ln in descripcion_block.splitlines():
        lines.append('  ' + ln.rstrip())
    lines.append('Requerimientos:')
    if requirements:
        for r in requirements:
            lines.append(f'- {r}')
    else:
        lines.append('- ')
    return '\n'.join(lines) + '\n'


def save_training_pair(original_text, predicted_yaml):
    os.makedirs(os.path.dirname(TRAIN_FILE), exist_ok=True)
    obj = {"text": original_text, "yaml": predicted_yaml}
    with open(TRAIN_FILE, 'a', encoding='utf-8') as f:
        f.write(json.dumps(obj, ensure_ascii=False) + '\n')


def main():
    global DEBUG
    parser = argparse.ArgumentParser()
    parser.add_argument('--debug', action='store_true', help='Imprimir informaci√≥n de depuraci√≥n sobre candidatos/company scores')
    parser.add_argument('path', nargs='?', help='vacante.txt (opcional, stdin si no)')
    args = parser.parse_args()

    # EXTRACT_DEBUG env var tiene prioridad si est√° definida (√∫til para CI)
    DEBUG = os.environ.get('EXTRACT_DEBUG', '0') == '1' or args.debug

    path = args.path
    raw = read_input(path)
    text = dedent(raw).strip()

    cargo, empresa = guess_title_and_company(text)

    if cargo and 'logo' in cargo.lower():
        lines = simple_clean_lines(text)
        for ln in lines[:20]:
            if looks_like_role(ln, lines_context=lines) and 'logo' not in ln.lower():
                cargo = ln
                break

    # conservative default for empresa handled inside guess_title_and_company

    bullets = extract_bullets_from_text(text)
    cleaned = [clean_requirement(b) for b in bullets]
    if not cleaned:
        cleaned = [
            "Gestionar requerimientos de an√°lisis de datos para clientes y equipo interno.",
            "Automatizar procesos usando Python o R, optimizando recursos y tiempos.",
            "Detectar tendencias y oportunidades para mejorar reportes e impulsar decisiones estrat√©gicas.",
            "Colaborar con √°reas como Producto, Ingenier√≠a y Operaciones."
        ]

    descripcion_block = dedent("""\
      üì¢ Estamos buscando un Data & Insights Analyst
      Una empresa de tecnolog√≠a en crecimiento con presencia en Latinoam√©rica est√° en la b√∫squeda de un Data & Insights Analyst para unirse a su equipo en Colombia.""").strip()

    fecha_iso = date.today().isoformat()

    yaml_text = format_yaml(cargo, empresa, fecha_iso, descripcion_block, cleaned)

    with open(OUT_YAML, 'w', encoding='utf-8', newline='\n') as f:
        f.write(yaml_text)

    save_training_pair(text, yaml_text)

    print(f'Archivo generado: {OUT_YAML}')
    print()
    print(yaml_text)


if __name__ == '__main__':
    main()